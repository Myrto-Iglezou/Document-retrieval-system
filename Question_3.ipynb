{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Question_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Myrto-Iglezou/AI2-project4/blob/master/Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOoUR08ESUJj"
      },
      "source": [
        "## YΣ19 Artificial Intelligence II\n",
        "# Homework 4\n",
        "\n",
        "### Iglezou Myrto - 111520170038"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ef8dyqplmv_"
      },
      "source": [
        "# Project Description\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjtCURBonpls"
      },
      "source": [
        "Build a BERT-based model which returns “an answer”, given a user question and a\r\n",
        "passage which includes the answer of the question. For this question answering task, we\r\n",
        "will use the SQuAD 2.0 dataset. We will start with the BERT-base pretrained model “bert-base-uncased”\r\n",
        "and fine-tune it to have a question answering task.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX2R8NAZcZpK"
      },
      "source": [
        "# **Question 3** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnA7Kn6DTGw3"
      },
      "source": [
        "### Load SCuAD 2.0 dataset from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ruuo--TQVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916b85a1-fa79-4406-ed65-88f908d6acce"
      },
      "source": [
        "import io\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "import pandas as pd \r\n",
        "import json\r\n",
        "import sys\r\n",
        "\r\n",
        "drive.mount('/content/drive',force_remount=True)\r\n",
        "\r\n",
        "sys.path.append('/content/drive/My Drive/')\r\n",
        "\r\n",
        "!cp -r \"/content/drive/My Drive/train-v2.0.json\" '/content/'\r\n",
        "!cp -r \"/content/drive/My Drive/utils_squad.py\" '/content/'\r\n",
        "!cp -r \"/content/drive/My Drive/utils_squad_evaluate.py\" '/content/'\r\n",
        "\r\n",
        "squad_file = '/content/train-v2.0.json'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1-BtrfXWokI"
      },
      "source": [
        "**utils_squad** is a library that helps handle the SQuAD dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyZR4BnGQKYY",
        "outputId": "0de54885-b39a-4a2a-cb49-544d70ba83bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "from utils_squad import (read_squad_examples, convert_examples_to_features,\r\n",
        "                         RawResult, write_predictions,\r\n",
        "                         RawResultExtended, write_predictions_extended)\r\n",
        "from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad, plot_pr_curve"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d0a168056879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from utils_squad import (read_squad_examples, convert_examples_to_features,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mRawResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          RawResultExtended, write_predictions_extended)\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils_squad_evaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEVAL_OPTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mevaluate_on_squad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_pr_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_squad.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Required by XLNet evaluation method to compute optimal threshold (see write_predictions_extended() method)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev1vzsRcU6Jx"
      },
      "source": [
        "data = read_squad_examples(input_file=squad_file,\r\n",
        "                                is_training=True,\r\n",
        "                                version_2_with_negative=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug8SwSkZ_uTB"
      },
      "source": [
        "train_data = pd.DataFrame.from_records([vars(line) for line in data])\r\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRdOa4hCZg9G"
      },
      "source": [
        "features = convert_examples_to_features(examples=data,\r\n",
        "                                        tokenizer=tokenizer,\r\n",
        "                                        max_seq_length=max_seq_length,\r\n",
        "                                        doc_stride=doc_stride,\r\n",
        "                                        max_query_length=max_query_length,\r\n",
        "                                        is_training=True)\r\n",
        "  torch.save(features, cached_features_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIt22mNknCAN"
      },
      "source": [
        "import torch\r\n",
        "# First checking if GPU is available\r\n",
        "train_on_gpu=torch.cuda.is_available()\r\n",
        "\r\n",
        "if(train_on_gpu):\r\n",
        "    print('Training on GPU.')\r\n",
        "    device = 'cuda'\r\n",
        "else:\r\n",
        "    print('No GPU available, training on CPU.')\r\n",
        "    device = 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFi3U07nzGJ-"
      },
      "source": [
        "%%capture\r\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTmTzd0WzLCu"
      },
      "source": [
        "import torch\r\n",
        "from transformers import BertTokenizer, BertModel\r\n",
        "from transformers import BertForQuestionAnswering\r\n",
        "\r\n",
        "# Load pre-trained model tokenizer (vocabulary)\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu9jcIFM-eMi"
      },
      "source": [
        "## References\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   https://github.com/nlpyang/pytorch-transformers/tree/master/examples\r\n",
        "\r\n"
      ]
    }
  ]
}